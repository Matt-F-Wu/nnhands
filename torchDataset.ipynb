{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Main purpose of this notebook is to get our data loaded into Torch such that we can start experimenting with NN\n",
    "\n",
    "Following:\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import random_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PIL import Image\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available(): \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "Lets load our csv into our dataset class and do a quick sanity check to see if our data is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandDataset(Dataset):\n",
    "    \"\"\"3D Hand Pose dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to csv file\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "        \"\"\"\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        self.transform = kwargs.get('transform',None)\n",
    "        self.train = kwargs.get('train', True)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def gaussian_2d(self, idx, std):\n",
    "        pos_2d = self.csv.iloc[idx, (21*3)+1:].as_matrix().astype(float)\n",
    "        pos_2d = pos_2d.reshape(21,2)\n",
    "        w, h = 480, 640\n",
    "        heatmap = np.zeros((21, w, h))\n",
    "        \n",
    "        rv = norm(loc=0, scale=std)\n",
    "        \n",
    "        for i, pos in enumerate(pos_2d):\n",
    "            pos_start_x, pos_end_x = int(pos[0]-std*4), int(pos[0]+std*4)\n",
    "            pos_start_y, pos_end_y = int(pos[1]-std*4), int(pos[0]+std*4)\n",
    "            \n",
    "            pos_start_x = np.minimum(pos_start_x, 0)\n",
    "            pos_start_y = np.minimum(pos_start_y, 0)\n",
    "            pos_end_x = np.maximum(pos_end_x, w)\n",
    "            pos_end_y = np.maximum(pos_end_y, h)\n",
    "            \n",
    "            for j in range(pos_start_x, pos_end_x):\n",
    "                for k in range(pos_start_y, pos_end_y):\n",
    "                    dist = np.linalg.norm((j,k)-pos)\n",
    "                    heatmap[i,j,k] = rv.pdf(dist)\n",
    "        return heatmap\n",
    "            \n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.csv.iloc[idx,0]\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        pos_3d = self.csv.iloc[idx, 1:(21*3)+1].as_matrix().astype(float)\n",
    "        pos_3d = pos_3d.reshape(21,3)\n",
    "\n",
    "        pos_2d = self.csv.iloc[idx, (21*3)+1:].as_matrix().astype(float)\n",
    "        pos_2d = pos_2d.reshape(21,2)\n",
    "        \n",
    "        heatmap_2d = None # Enabling it is super slow right now...\n",
    "        #heatmap_2d = self.gaussian_2d(idx,3)\n",
    "        \n",
    "        sample = {'image': image,\n",
    "                  'pos_3d': pos_3d,\n",
    "                  'pos_2d': pos_2d,\n",
    "                  'heatmap_2d': heatmap_2d}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        pos_3d, pos_2d = sample['pos_3d'], sample['pos_2d']\n",
    "        # swap color axis\n",
    "        image = image.transpose((2,0,1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "               'pos_3d': torch.from_numpy(pos_3d),\n",
    "               'pos_2d': torch.from_numpy(pos_2d),\n",
    "               'heatmap_2d': torch.from_numpy(heatmap_2d)}\n",
    "    \n",
    "class Scale(object):\n",
    "    def __init__(self, s):\n",
    "        self.s = s\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        pos_3d, pos_2d = sample['pos_3d'], sample['pos_2d']\n",
    "        image = Image.fromarray(image)\n",
    "        width, height = image.width, image.height\n",
    "        s_width, s_height = int(width*self.s), int(height*self.s)\n",
    "        \n",
    "        image = image.resize((s_width, s_height))\n",
    "        image = np.array(image).reshape((s_height, s_width, 3))\n",
    "        \n",
    "        pos_3d = pos_3d*self.s\n",
    "        pos_2d = pos_2d*self.s\n",
    "        \n",
    "        return {'image': image,\n",
    "               'pos_3d': pos_3d,\n",
    "               'pos_2d': pos_2d,\n",
    "               'heatmap_2d': heatmap_2d}\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handDataset = HandDataset('train_dataset.csv', transform=Scale(1))\n",
    "sample = handDataset[np.random.randint(len(handDataset))]\n",
    "\n",
    "def show_joints(image, pos_2d, pos_3d, heatmap_2d):\n",
    "    fig = plt.figure(figsize=plt.figaspect(2.))\n",
    "    ax = fig.add_subplot(2,1,1)\n",
    "    height, width, depth = image.shape\n",
    "    ax.imshow(image)\n",
    "    for joint in heatmap_2d:\n",
    "        ax.imshow(joint)\n",
    "    ax.scatter(pos_2d[:,0], pos_2d[:, 1], s=10, marker='.', c='r')\n",
    "    ax = fig.add_subplot(2,1,2, projection=\"3d\")\n",
    "    ax.set_xlim(-height/2, height/2)\n",
    "    ax.set_ylim(-width/2, width/2)\n",
    "    ax.view_init(-90,-90)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.scatter(pos_3d[:,0], pos_3d[:,1], pos_3d[:,2], s=30)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_joints(sample['image'], sample['pos_2d'], sample['pos_3d'],\n",
    "           sample['heatmap_2d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1) # \"flatten\" the C * H * W values into a single vector\n",
    "\n",
    "def random_weight(shape): \n",
    "    \"\"\"\n",
    "    Create random Tensors for weights; setting requires_grad=True means that we\n",
    "    want to compute gradients for these Tensors during the backward pass.\n",
    "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2: # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH,kW]\n",
    "        \n",
    "    # randn is standard normal distribution generator.\n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in) \n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "\n",
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    Scale(0.5),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "hand_train = HandDataset('dataset.csv', transform=transform, train=True)\n",
    "N = len(hand_train)\n",
    "loader_train = DataLoader(hand_train, batch_size=64,\n",
    "            sampler=sampler.SubsetRandomSampler(range(int(N*0.8))))\n",
    "\n",
    "hand_val = HandDataset('dataset.csv', transform=transform, train=True)\n",
    "loader_val = DataLoader(hand_val, batch_size=64,\n",
    "            sampler=sampler.SubsetRandomSampler(range(int(N*0.8), int(N*0.9))))\n",
    "\n",
    "hand_test = HandDataset('dataset.csv', transform=transform, train=False)\n",
    "loader_test = DataLoader(hand_test, batch_size=64,\n",
    "                         sampler=sampler.SubsetRandomSampler(range(int(N*0.9),N)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([64, 3, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i_batch, sample_batched in enumerate(loader_train):\n",
    "    print(i_batch, sample_batched['image'].size())\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
